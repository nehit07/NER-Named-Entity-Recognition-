{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"0353206b4ecc48918cc437bd56c79ac2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c45678215bcb4eb492a4c8d3a167b00e","placeholder":"​","style":"IPY_MODEL_6617689f413b41dd99869e605a38a229","value":"Map: 100%"}},"049930df1df7470e9fed486c26501194":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06e6d7fb286a4afb882829d830a6e64a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b355f9156c994cefa8b4c671b2c33f54","placeholder":"​","style":"IPY_MODEL_27fda45f132a4df599b43285b9e92874","value":" 14041/14041 [00:03&lt;00:00, 3952.49 examples/s]"}},"248abf05b4ac4174835fc612f388b2ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b3550f71f4c4b859f51dbb9c6777419","max":3453,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82a6acf143d94860bd2e7f9f92f158a0","value":3453}},"27fda45f132a4df599b43285b9e92874":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"316d73433d844e3dbae4df772e7461fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32ae2de6b3c148c3bd3bd0791b051abf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b0eafd7ce64660a6fc979a62cecef7","placeholder":"​","style":"IPY_MODEL_45df78ec7ad24becbbc0ba240929a696","value":"Map: 100%"}},"3b2bd5cb13164e3cb93f0700cafaec0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b3550f71f4c4b859f51dbb9c6777419":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b0eafd7ce64660a6fc979a62cecef7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45df78ec7ad24becbbc0ba240929a696":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4730bfc6fdc046278887a6beaa0b3faf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63cb655f5a2c40f7a4b18035a325c0c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32ae2de6b3c148c3bd3bd0791b051abf","IPY_MODEL_248abf05b4ac4174835fc612f388b2ed","IPY_MODEL_a34cfca16e6f458281aa58f988b6da98"],"layout":"IPY_MODEL_a7c0cfacc9e94965b5d1ed15dc6b2438"}},"6617689f413b41dd99869e605a38a229":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74c9e459f8154e2bad356c4bbd25d617":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0353206b4ecc48918cc437bd56c79ac2","IPY_MODEL_d3eccfa19e6243b5b7edec19a0aff0f9","IPY_MODEL_793f97c6a9f84df7905a15d1fce1199f"],"layout":"IPY_MODEL_fbfe171c00c74c118c336b8e99777253"}},"793f97c6a9f84df7905a15d1fce1199f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3385c6e537f4526861f15ebd241c748","placeholder":"​","style":"IPY_MODEL_d027207772d94acabb6f66c6672a0946","value":" 3250/3250 [00:00&lt;00:00, 3798.09 examples/s]"}},"82a6acf143d94860bd2e7f9f92f158a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9983b7dde69546e48a76be2044362158":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da21a07068dc42eabceb3018dc5df2ee","IPY_MODEL_dcc7c0d0c003417fa571f3171540c48c","IPY_MODEL_06e6d7fb286a4afb882829d830a6e64a"],"layout":"IPY_MODEL_cd3f27af556144a0a045822867a91502"}},"a34cfca16e6f458281aa58f988b6da98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2f56eb36d5b4e7ca7dd258ec3f87c3a","placeholder":"​","style":"IPY_MODEL_4730bfc6fdc046278887a6beaa0b3faf","value":" 3453/3453 [00:00&lt;00:00, 4177.07 examples/s]"}},"a7c0cfacc9e94965b5d1ed15dc6b2438":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae2ee723ca2349c280fdf660b335845f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b355f9156c994cefa8b4c671b2c33f54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde85138c44f4cafa591f78d579d1003":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c45678215bcb4eb492a4c8d3a167b00e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd3f27af556144a0a045822867a91502":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d027207772d94acabb6f66c6672a0946":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3eccfa19e6243b5b7edec19a0aff0f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b2bd5cb13164e3cb93f0700cafaec0d","max":3250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bde85138c44f4cafa591f78d579d1003","value":3250}},"da21a07068dc42eabceb3018dc5df2ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef77240a62734de5b503ce8425d54eb4","placeholder":"​","style":"IPY_MODEL_049930df1df7470e9fed486c26501194","value":"Map: 100%"}},"dcc7c0d0c003417fa571f3171540c48c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae2ee723ca2349c280fdf660b335845f","max":14041,"min":0,"orientation":"horizontal","style":"IPY_MODEL_316d73433d844e3dbae4df772e7461fa","value":14041}},"e3385c6e537f4526861f15ebd241c748":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef77240a62734de5b503ce8425d54eb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2f56eb36d5b4e7ca7dd258ec3f87c3a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbfe171c00c74c118c336b8e99777253":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets\n!pip install transformers\n!pip install seqeval","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-02-20T13:11:38.560352Z","iopub.execute_input":"2025-02-20T13:11:38.560712Z","iopub.status.idle":"2025-02-20T13:11:49.379458Z","shell.execute_reply.started":"2025-02-20T13:11:38.560687Z","shell.execute_reply":"2025-02-20T13:11:49.378435Z"},"id":"Htmq5VT2a_BG","outputId":"306049ba-d1b2-4128-d90b-edf17f4959bd","trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.11)\nRequirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.28.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport transformers\nimport shutil\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification,\n)\nfrom seqeval.metrics import classification_report\nfrom google.colab import files","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:12:45.796876Z","iopub.execute_input":"2025-02-20T13:12:45.797223Z","iopub.status.idle":"2025-02-20T13:12:45.824500Z","shell.execute_reply.started":"2025-02-20T13:12:45.797195Z","shell.execute_reply":"2025-02-20T13:12:45.823607Z"},"id":"tGtPCl9jZ3cy","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class NERModel:\n  def __init__(self, model_name=\"bert-base-cased\", dataset_name=\"conll2003\", output_dir=\"./ner_trained_model\"):\n    self.model_name = model_name\n    self.dataset_name = dataset_name\n    self.output_dir = output_dir\n\n    self._load_dataset()\n    self._load_tokenizer()\n    self._prepare_data()\n    self._load_model()\n    self._set_training_arguments()\n\n  def _load_dataset(self):\n    print(\"Loading Dataset...\")\n    self.dataset = load_dataset(self.dataset_name)\n\n  def _load_tokenizer(self):\n    print(\"Loading Tokenizer...\")\n    self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n\n  def _tokenize_and_align_labels(self, examples):\n    tokenized_inputs = self.tokenizer(examples[\"tokens\"], truncation=True, padding=True, is_split_into_words=True)\n    labels = []\n\n    for i, label in enumerate(examples[\"ner_tags\"]):\n      word_ids = tokenized_inputs.word_ids(batch_index=i)\n      previous_word = None\n      label_ids = []\n\n      for word_idx in word_ids:\n        if word_idx is None:\n          label_ids.append(-100)\n        elif word_idx != previous_word:\n          label_ids.append(label[word_idx])\n        else:\n          label_ids.append(label[word_idx])\n        previous_word = word_idx\n      labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n\n  def _prepare_data(self):\n    print(\"Tokenizing dataset...\")\n    self.tokenized_datasets = self.dataset.map(self._tokenize_and_align_labels, batched=True)\n\n  def _load_model(self):\n    print(\"Loading Model...\")\n    num_labels = len(self.dataset[\"train\"].features[\"ner_tags\"].feature.names)\n    self.model = AutoModelForTokenClassification.from_pretrained(self.model_name, num_labels=num_labels)\n\n  def _set_training_arguments(self):\n    print(\"Setting training arguments...\")\n    per_device_train_batch_size = min(16, max(1, torch.cuda.device_count()) * 8)\n    self.training_args = TrainingArguments(\n      output_dir=self.output_dir,\n      evaluation_strategy=\"epoch\",\n      save_strategy=\"epoch\",\n      logging_strategy=\"epoch\",\n      learning_rate=2e-5,\n      per_device_train_batch_size=per_device_train_batch_size,\n      per_device_eval_batch_size=16,\n      num_train_epochs=5,\n      weight_decay=0.01,\n      save_total_limit=2,\n      load_best_model_at_end = True,\n      metric_for_best_model = \"f1\",\n      report_to=\"none\",\n    )\n\n  def _compute_metrics(self, pred):\n    predictions, labels = pred\n    predictions = np.argmax(predictions, axis=2)\n    label_list = self.dataset[\"train\"].features[\"ner_tags\"].feature.names\n    true_labels = [\n        [label_list[label] for label in label_seq if label != -100]\n        for label_seq in labels\n    ]\n    true_predictions = [\n        [label_list[pred] for pred, label in zip(pred_seq, label_seq) if label != -100]\n        for pred_seq, label_seq in zip(predictions, labels)\n    ]\n    report = classification_report(true_labels, true_predictions, output_dict=True)\n    metrics = {\n        \"eval_loss\": report[\"weighted avg\"][\"precision\"],  # Example loss mapping\n        \"eval_f1\": report[\"macro avg\"][\"f1-score\"],  # Extract macro F1 score\n        \"eval_macro avg\": report[\"macro avg\"][\"f1-score\"],\n        \"eval_weighted avg\": report[\"weighted avg\"][\"f1-score\"],\n    }\n    return metrics\n\n    # def _compute_metrics(self, pred):\n    #     predictions, labels = pred\n    #     predictions = np.argmax(predictions, axis=2)\n    #     label_list = self.dataset[\"train\"].features[\"ner_tags\"].feature.names\n\n    #     true_labels = [\n    #         [label_list[label] for label in label_seq if label != -100]\n    #         for label_seq in labels\n    #     ]\n    #     true_predictions = [\n    #         [label_list[pred] for pred, label in zip(pred_seq, label_seq) if label != -100]\n    #         for pred_seq, label_seq in zip(predictions, labels)\n    #     ]\n\n    #     return classification_report(true_labels, true_predictions, output_dict=True)\n\n\n  def train(self):\n    print(\"Initializing trainer...\")\n    trainer = Trainer(\n        model = self.model,\n        args = self.training_args,\n        train_dataset = self.tokenized_datasets[\"train\"],\n        eval_dataset = self.tokenized_datasets[\"validation\"],\n        tokenizer=self.tokenizer,\n        data_collator = DataCollatorForTokenClassification(tokenizer=self.tokenizer),\n        compute_metrics = self._compute_metrics,\n    )\n\n    print(\"Training Model...\")\n    trainer.train()\n    \n    print(\"Saving trained model...\")\n    self.model.save_pretrained(self.output_dir)\n    self.tokenizer.save_pretrained(self.output_dir)\n    print(\"Model saved successfully!\")\n\n    \n    # Also save the model in .h5 format for loading in inference\n    h5_model_path = f\"{self.output_dir}/ner_trained_model.h5\"\n    torch.save(self.model.state_dict(), h5_model_path)\n    print(f\"Model also saved in .h5 format at: {h5_model_path}\")\n\n    shutil.make_archive(\"ner_trained_model\", 'zip', self.output_dir)\n    print(\"Model zipped successfully!\")\n\n    files.download(\"ner_trained_model.zip\")\n    print(\"Model download started...\")","metadata":{"execution":{"iopub.status.busy":"2025-02-20T13:12:48.958294Z","iopub.execute_input":"2025-02-20T13:12:48.958629Z","iopub.status.idle":"2025-02-20T13:12:48.973146Z","shell.execute_reply.started":"2025-02-20T13:12:48.958600Z","shell.execute_reply":"2025-02-20T13:12:48.972119Z"},"id":"cNKgQRcAbbM_","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if __name__ == \"__main__\":\n  ner = NERModel()\n  ner.train()","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["9983b7dde69546e48a76be2044362158","da21a07068dc42eabceb3018dc5df2ee","dcc7c0d0c003417fa571f3171540c48c","06e6d7fb286a4afb882829d830a6e64a","cd3f27af556144a0a045822867a91502","ef77240a62734de5b503ce8425d54eb4","049930df1df7470e9fed486c26501194","ae2ee723ca2349c280fdf660b335845f","316d73433d844e3dbae4df772e7461fa","b355f9156c994cefa8b4c671b2c33f54","27fda45f132a4df599b43285b9e92874","74c9e459f8154e2bad356c4bbd25d617","0353206b4ecc48918cc437bd56c79ac2","d3eccfa19e6243b5b7edec19a0aff0f9","793f97c6a9f84df7905a15d1fce1199f","fbfe171c00c74c118c336b8e99777253","c45678215bcb4eb492a4c8d3a167b00e","6617689f413b41dd99869e605a38a229","3b2bd5cb13164e3cb93f0700cafaec0d","bde85138c44f4cafa591f78d579d1003","e3385c6e537f4526861f15ebd241c748","d027207772d94acabb6f66c6672a0946","63cb655f5a2c40f7a4b18035a325c0c0","32ae2de6b3c148c3bd3bd0791b051abf","248abf05b4ac4174835fc612f388b2ed","a34cfca16e6f458281aa58f988b6da98","a7c0cfacc9e94965b5d1ed15dc6b2438","43b0eafd7ce64660a6fc979a62cecef7","45df78ec7ad24becbbc0ba240929a696","3b3550f71f4c4b859f51dbb9c6777419","82a6acf143d94860bd2e7f9f92f158a0","f2f56eb36d5b4e7ca7dd258ec3f87c3a","4730bfc6fdc046278887a6beaa0b3faf"]},"execution":{"iopub.status.busy":"2025-02-20T13:12:53.555890Z","iopub.execute_input":"2025-02-20T13:12:53.556206Z","iopub.status.idle":"2025-02-20T13:37:25.518775Z","shell.execute_reply.started":"2025-02-20T13:12:53.556180Z","shell.execute_reply":"2025-02-20T13:37:25.518088Z"},"id":"08KUJYOrakoD","outputId":"c86c23a5-8d4e-4f00-bd1d-95c204592345","trusted":true},"outputs":[{"name":"stdout","text":"Loading Dataset...\nLoading Tokenizer...\nTokenizing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14041 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf111f1c41614b73bd683a542b5c5aaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a0f0a647fe434c86713079cd8640be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3453 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7d2908ece3e42b4a51920c1307dbd7c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Loading Model...\nSetting training arguments...\nInitializing trainer...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n<ipython-input-7-25a67c627a0c>:111: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"Training Model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2195/2195 21:37, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>Macro avg</th>\n      <th>Weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.221700</td>\n      <td>0.075857</td>\n      <td>0.887562</td>\n      <td>0.887562</td>\n      <td>0.905427</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.055900</td>\n      <td>0.069914</td>\n      <td>0.916425</td>\n      <td>0.916425</td>\n      <td>0.929731</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.032600</td>\n      <td>0.060618</td>\n      <td>0.921673</td>\n      <td>0.921673</td>\n      <td>0.935555</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.020000</td>\n      <td>0.063528</td>\n      <td>0.925757</td>\n      <td>0.925757</td>\n      <td>0.939494</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.015100</td>\n      <td>0.066606</td>\n      <td>0.921574</td>\n      <td>0.921574</td>\n      <td>0.934611</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Saving trained model...\nModel saved successfully!\nModel also saved in .h5 format at: ./ner_trained_model/ner_trained_model.h5\nModel zipped successfully!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"download(\"download_6e282bcf-ffbe-4e33-be6f-7de8abc65691\", \"ner_trained_model.zip\", 3018783866)"},"metadata":{}},{"name":"stdout","text":"Model download started...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the trained model before inference\nmodel_path = \"/kaggle/working/ner_trained_model.h5\"\nmodel = load_model(model_path)\nprint(\"Model loaded successfully for inference.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T12:53:23.363261Z","iopub.status.idle":"2025-02-20T12:53:23.363607Z","shell.execute_reply":"2025-02-20T12:53:23.363487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2025-02-20T12:53:23.364458Z","iopub.status.idle":"2025-02-20T12:53:23.364831Z","shell.execute_reply":"2025-02-20T12:53:23.364651Z"},"id":"u4GSDsgVgt09","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class NERInference:\n    def __init__(self, model_path):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n        self.model = AutoModelForTokenClassification.from_pretrained(model_path)\n        self.model.eval()\n        self.label_map = self.model.config.id2label\n\n    def predict(self, text):\n        tokens = self.tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\", is_split_into_words=False)\n\n        with torch.no_grad():\n            outputs = self.model(**tokens)\n\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=2)\n\n        tokens_list = self.tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0])\n        pred_labels = [self.label_map[int(p)] for p in predictions[0]]\n\n        entities = []\n        current_entity = None\n        for token, label in zip(tokens_list, pred_labels):\n            if label != \"O\": # Ignore 'O' (Outside labels)\n                if current_entity and current_entity[\"label\"] == label:\n                    current_entity[\"text\"] += \" \" + token\n                else:\n                    if current_entity:\n                        entities.append(current_entity)\n                    current_entity = {\"text\":token.replace(\"##\",\"\"), \"label\":label}\n            else:\n                if current_entity:\n                    entities.append(current_entity)\n                    current_entity = None\n\n        if current_entity:\n            entities.append(current_entity)\n\n        return entities","metadata":{"execution":{"iopub.status.busy":"2025-02-20T12:53:23.365996Z","iopub.status.idle":"2025-02-20T12:53:23.366475Z","shell.execute_reply":"2025-02-20T12:53:23.366330Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    model_path = \"/kaggle/working/ner_trained_model.h5\"\n    ner = NERInference(model_path)\n    text = \"Elon Musk founded SpaceX in 2002 and lives in Texas.\"\n    predictions = ner.predict(text)\n\n    merged_entities = []\n    current_text = \"\"\n    current_label = \"\"\n\n    for predicted in predictions:\n        token = predicted[\"text\"]\n        label = predicted[\"label\"]\n\n        if token.startswith(\"##\"):\n            current_text += token[2:]  # Merge subword with the previous word\n        else:\n            # Save the previous entity if it exists\n            if current_text and current_label and current_label != label:\n                merged_entities.append({\"text\": current_text, \"label\": current_label})\n                current_text = \"\"\n\n            # Start a new entity\n            if label != \"LABEL_0\":  # Ignore non-entity words\n                current_text = token\n                current_label = label\n\n    # Append the last entity if valid\n    if current_text and current_label:\n        merged_entities.append({\"text\": current_text, \"label\": current_label})\n\n    # Print extracted entities\n    print(\"Extracted Entities:\")\n    for entity in merged_entities:\n        print(f\"{entity['text']} - {entity['label']}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-02-20T12:53:23.367443Z","iopub.status.idle":"2025-02-20T12:53:23.367696Z","shell.execute_reply":"2025-02-20T12:53:23.367594Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport shutil\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom datasets import load_dataset\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:40:27.334637Z","iopub.execute_input":"2025-02-20T13:40:27.335037Z","iopub.status.idle":"2025-02-20T13:40:27.339256Z","shell.execute_reply.started":"2025-02-20T13:40:27.335006Z","shell.execute_reply":"2025-02-20T13:40:27.338404Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"!unzip -o ner_trained_model.zip -d ./ner_trained_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:40:39.607612Z","iopub.execute_input":"2025-02-20T13:40:39.607957Z","iopub.status.idle":"2025-02-20T13:41:12.500455Z","shell.execute_reply.started":"2025-02-20T13:40:39.607928Z","shell.execute_reply":"2025-02-20T13:41:12.499616Z"}},"outputs":[{"name":"stdout","text":"Archive:  ner_trained_model.zip\n  inflating: ./ner_trained_model/tokenizer_config.json  \n  inflating: ./ner_trained_model/ner_trained_model.h5  \n  inflating: ./ner_trained_model/tokenizer.json  \n  inflating: ./ner_trained_model/vocab.txt  \n  inflating: ./ner_trained_model/model.safetensors  \n  inflating: ./ner_trained_model/config.json  \n  inflating: ./ner_trained_model/special_tokens_map.json  \n  inflating: ./ner_trained_model/checkpoint-2195/tokenizer_config.json  \n  inflating: ./ner_trained_model/checkpoint-2195/scheduler.pt  \n  inflating: ./ner_trained_model/checkpoint-2195/tokenizer.json  \n  inflating: ./ner_trained_model/checkpoint-2195/vocab.txt  \n  inflating: ./ner_trained_model/checkpoint-2195/rng_state.pth  \n  inflating: ./ner_trained_model/checkpoint-2195/model.safetensors  \n  inflating: ./ner_trained_model/checkpoint-2195/trainer_state.json  \n  inflating: ./ner_trained_model/checkpoint-2195/config.json  \n  inflating: ./ner_trained_model/checkpoint-2195/optimizer.pt  \n  inflating: ./ner_trained_model/checkpoint-2195/special_tokens_map.json  \n  inflating: ./ner_trained_model/checkpoint-2195/training_args.bin  \n  inflating: ./ner_trained_model/checkpoint-1756/tokenizer_config.json  \n  inflating: ./ner_trained_model/checkpoint-1756/scheduler.pt  \n  inflating: ./ner_trained_model/checkpoint-1756/tokenizer.json  \n  inflating: ./ner_trained_model/checkpoint-1756/vocab.txt  \n  inflating: ./ner_trained_model/checkpoint-1756/rng_state.pth  \n  inflating: ./ner_trained_model/checkpoint-1756/model.safetensors  \n  inflating: ./ner_trained_model/checkpoint-1756/trainer_state.json  \n  inflating: ./ner_trained_model/checkpoint-1756/config.json  \n  inflating: ./ner_trained_model/checkpoint-1756/optimizer.pt  \n  inflating: ./ner_trained_model/checkpoint-1756/special_tokens_map.json  \n  inflating: ./ner_trained_model/checkpoint-1756/training_args.bin  \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"model_path = \"./ner_trained_model\"\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = AutoModelForTokenClassification.from_pretrained(model_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:41:18.777289Z","iopub.execute_input":"2025-02-20T13:41:18.777781Z","iopub.status.idle":"2025-02-20T13:41:18.872896Z","shell.execute_reply.started":"2025-02-20T13:41:18.777722Z","shell.execute_reply":"2025-02-20T13:41:18.872226Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset = load_dataset(\"conll2003\")  # Using the same dataset for labels\nlabel_list = dataset[\"train\"].features[\"ner_tags\"].feature.names","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:41:29.178984Z","iopub.execute_input":"2025-02-20T13:41:29.179328Z","iopub.status.idle":"2025-02-20T13:41:30.236684Z","shell.execute_reply.started":"2025-02-20T13:41:29.179304Z","shell.execute_reply":"2025-02-20T13:41:30.236033Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def predict_ner(text):\n    model.eval()\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n\n    with torch.no_grad():\n        outputs = model(**inputs).logits\n\n    predictions = torch.argmax(outputs, dim=2)\n    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n    predicted_labels = [label_list[pred] for pred in predictions[0]]\n\n    return list(zip(tokens, predicted_labels))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:43:35.843212Z","iopub.execute_input":"2025-02-20T13:43:35.843516Z","iopub.status.idle":"2025-02-20T13:43:35.848430Z","shell.execute_reply.started":"2025-02-20T13:43:35.843495Z","shell.execute_reply":"2025-02-20T13:43:35.847708Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"sample_text = \"Elon Musk is the CEO of Tesla, which is headquartered in California.\"\npredictions = predict_ner(sample_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:43:44.427153Z","iopub.execute_input":"2025-02-20T13:43:44.427448Z","iopub.status.idle":"2025-02-20T13:43:44.692790Z","shell.execute_reply.started":"2025-02-20T13:43:44.427426Z","shell.execute_reply":"2025-02-20T13:43:44.691859Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(\"\\nNamed Entity Recognition Results:\")\nfor token, label in predictions:\n    print(f\"{token} --> {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T13:43:49.365563Z","iopub.execute_input":"2025-02-20T13:43:49.365921Z","iopub.status.idle":"2025-02-20T13:43:49.372638Z","shell.execute_reply.started":"2025-02-20T13:43:49.365889Z","shell.execute_reply":"2025-02-20T13:43:49.371846Z"}},"outputs":[{"name":"stdout","text":"\nNamed Entity Recognition Results:\n[CLS] --> O\nEl --> B-PER\n##on --> B-PER\nMu --> I-PER\n##sk --> I-PER\nis --> O\nthe --> O\nCEO --> O\nof --> O\nTe --> B-ORG\n##sla --> B-ORG\n, --> O\nwhich --> O\nis --> O\nheadquartered --> O\nin --> O\nCalifornia --> B-LOC\n. --> O\n[SEP] --> O\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}